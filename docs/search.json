[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "myblog",
    "section": "",
    "text": "Machine Learning\n\n\nPython\n\n\n\n\nTheory along with code walkthough on the on the most essestial algorithm of Machine Learning\n\n\n\n\n\n\nNov 27, 2022\n\n\nShashank Shekhar\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nAzure\n\n\nFlask\n\n\nAPI\n\n\n\n\nIn this blog, I am going to show how to deploy a Machine Learning API on Azure App Service (Web App).\n\n\n\n\n\n\nNov 20, 2022\n\n\nShashank Shekhar\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nNov 13, 2022\n\n\nShashank Shekhar\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is start of my bloging journey. I will writing about Deep Learning and this assciated with it. The topics I would like to write about in near future are - Computer Vision, NLP, Machine Learning on Azure Cloud, Deployment of ML Application on Azure Cloud, MLOps.\nWith this I am also takaing a 12-Week Blog Challenge, where ober the course of next 12 Weeks I will be writing - (atleast)1 Blog a week."
  },
  {
    "objectID": "posts/linear-regression/Linear_Regression.html",
    "href": "posts/linear-regression/Linear_Regression.html",
    "title": "Linear Regression - A Deep Dive!",
    "section": "",
    "text": "By the end of this blog you will bw able to understand:\n\nWhat is Regression and classification?\nDifference between Simple Linear Regression and Multiple Linear Regression.\nHyothesis(model) of Linear Regression\nCost function\nGradient Descent\nHow to code all these equation and algorithm in Python?\n\n\n\nRegression vs Classification\nIn Machine Learning, If the output variable has continous range, and we have to find the relationship between the the input and output variable(s). This is called Regression. Examples include - House Price, Salary, etc\nIn contrast, if the the output has descrete range. It is then called Classification. Examples include - Cat vs Dog, Spam/Not Spam, etc\nThese regresssion models can be used for both Inference and Prediction.\nIn this blog we are focused to get Prediction using Regression.\n\n\nRegression\nRegression in itself can be of multiple types - Linear and Non-Linear Regression.\nLinear Regression - When the model relates the input and output varibale in straight line. Non-Linear Regression - When the model relates the input and output varibale in curved line.\n\n\nRegression\nIn this notebook we are going to implement Linear Regression on a small dataset.\n\n# Imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nWe are using a small dataset from here. This a data about Cricket Chirps Vs. Temperature. We will use linear regression to fit model.\n\n# loading data\ndata = pd.read_excel('slr02.xls')\n\n*** No CODEPAGE record, no encoding_override: will use 'ascii'\n\n\nNow we look into data we see there are two columns X and Y.\nwere X = chirps/sec for the striped ground cricket\nand Y = temperature in degrees Fahrenheit\n\n# visualise data\ndata\n\n\n\n\n\n  \n    \n      \n      X\n      Y\n    \n  \n  \n    \n      0\n      20.000000\n      88.599998\n    \n    \n      1\n      16.000000\n      71.599998\n    \n    \n      2\n      19.799999\n      93.300003\n    \n    \n      3\n      18.400000\n      84.300003\n    \n    \n      4\n      17.100000\n      80.599998\n    \n    \n      5\n      15.500000\n      75.199997\n    \n    \n      6\n      14.700000\n      69.699997\n    \n    \n      7\n      17.100000\n      82.000000\n    \n    \n      8\n      15.400000\n      69.400002\n    \n    \n      9\n      16.200001\n      83.300003\n    \n    \n      10\n      15.000000\n      79.599998\n    \n    \n      11\n      17.200001\n      82.599998\n    \n    \n      12\n      16.000000\n      80.599998\n    \n    \n      13\n      17.000000\n      83.500000\n    \n    \n      14\n      14.400000\n      76.300003\n    \n  \n\n\n\n\n\ntype(data)\n\npandas.core.frame.DataFrame\n\n\n\n# data we got are in pandas dataframe format\n# we need to cast it in numpy array for calulations\nX = np.array(data.X)\ny = np.array(data.Y)\n\nNow we have two arrays. One containing input features and other array has output features\n\n# visualise casted data\nX,y\n\n(array([20.        , 16.        , 19.79999924, 18.39999962, 17.10000038,\n        15.5       , 14.69999981, 17.10000038, 15.39999962, 16.20000076,\n        15.        , 17.20000076, 16.        , 17.        , 14.39999962]),\n array([88.59999847, 71.59999847, 93.30000305, 84.30000305, 80.59999847,\n        75.19999695, 69.69999695, 82.        , 69.40000153, 83.30000305,\n        79.59999847, 82.59999847, 80.59999847, 83.5       , 76.30000305]))\n\n\n\ntype(X)\n\nnumpy.ndarray\n\n\n\n# function for plotting data points\ndef plot_points(X, y, xlabel, ylabel):\n    \"\"\"Plot points given X and Y co-ordinates and labels them\"\"\"\n    plt.plot(X, y, 'o')\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n\n\n# plot data points\nplot_points(X, y, \"chirps/sec for the striped ground cricket\", \"temperature in degrees Fahrenheit\")\n\n\n\n\nWe have initialised theta to a random value. We then create hypothesis for model which is linear in nature\n\n# initialised theta\nnp.random.seed(2)\ntheta = np.random.rand(2,1)\n# hypothesis of model\ndef hypothesis(X, theta):\n    \"\"\"Predicts output feature given input feature and theta\"\"\"\n    return theta[0] + theta[1] * X\n\nWe want to draw our line of regression to see if fit data correctly.\n\n# plots line of regression\ndef draw_line(theta):\n    \"\"\"Plot a line from slope and intercept\"\"\"\n    axes = plt.gca()\n    x_vals = np.array(axes.get_xlim())\n    y_vals = hypothesis(x_vals, theta)\n    plt.plot(x_vals, y_vals, '--')\n\nWe want to plot data points and line of regession on same plot to see if we are progressing as we train our model\n\n# plots points and lines\ndef draw_points_and_lines(X, y, xlabel, ylabel, theta):\n    \"\"\"Draws lines and points\"\"\"\n    plot_points(X, y, xlabel, ylabel)\n    draw_line(theta)\n\nNow without training our model letâ€™s were the line of regression lies\n\n# draw line of regression without traing model\ndraw_points_and_lines(X, y, \"chirps/sec for the striped ground cricket\", \"temperature in degrees Fahrenheit\", theta)\n\n\n\n\nCost function givies us measure of how much we are error we have\nwe need to minimize it. Here we have used sqared error cost function which basically sums over all the sqared error of indivisual points\n\n# cost function\nm = len(X)\ndef cost(X, y, theta):\n    \"\"\"Returns cost\"\"\"\n    return (1/(2*m)) * np.sum((hypothesis(X, theta) - y) ** 2)\n\n\n# initial cost without trraining model\ncost(X, y, theta)\n\n3154.8870744571304\n\n\n\n(hypothesis(X, theta) - y), X\n\n(array([-87.64547893, -70.74918386, -92.35066878, -83.38696549,\n        -79.72066499, -74.36214545, -68.88288644, -81.12066652,\n        -68.56474267, -82.44400317, -78.77511009, -81.71807236,\n        -79.74918386, -82.62325916, -75.49067042]),\n array([20.        , 16.        , 19.79999924, 18.39999962, 17.10000038,\n        15.5       , 14.69999981, 17.10000038, 15.39999962, 16.20000076,\n        15.        , 17.20000076, 16.        , 17.        , 14.39999962]))\n\n\nNow we will minimize cost with help of gradient descent\n\n# minimize cost\ndef gradient_descent(X, y, theta, alpha, steps):\n    for i in range(steps):\n        old_cost = cost(X, y, theta)\n        temp0 = theta[0] - alpha * ((1/m) * np.sum(hypothesis(X, theta) - y))\n        temp1 = theta[1] - alpha * ((1/m) * np.dot((hypothesis(X, theta) - y), X))\n        theta[0] = temp0\n        theta[1] = temp1\n        new_cost = cost(X, y, theta)\n        if new_cost > old_cost:\n            print(\"WARNING!!! COST INCREASING\")\n        else:\n            print(\"Cost Decresing\", new_cost)\n\n\n# train model of 100 iterations\ngradient_descent(X, y, theta, alpha=0.0001, steps=100)\ntheta\n\nCost Decresing 9.24630550184814\nCost Decresing 9.246299931707105\nCost Decresing 9.246294361576792\nCost Decresing 9.246288791457197\nCost Decresing 9.246283221348309\nCost Decresing 9.246277651250153\nCost Decresing 9.246272081162708\nCost Decresing 9.246266511085983\nCost Decresing 9.246260941019973\nCost Decresing 9.246255370964697\nCost Decresing 9.246249800920113\nCost Decresing 9.246244230886267\nCost Decresing 9.246238660863133\nCost Decresing 9.246233090850716\nCost Decresing 9.246227520849024\nCost Decresing 9.24622195085804\nCost Decresing 9.246216380877774\nCost Decresing 9.246210810908229\nCost Decresing 9.246205240949406\nCost Decresing 9.24619967100129\nCost Decresing 9.246194101063905\nCost Decresing 9.246188531137236\nCost Decresing 9.246182961221276\nCost Decresing 9.246177391316046\nCost Decresing 9.246171821421523\nCost Decresing 9.246166251537723\nCost Decresing 9.246160681664634\nCost Decresing 9.246155111802265\nCost Decresing 9.24614954195063\nCost Decresing 9.246143972109698\nCost Decresing 9.246138402279486\nCost Decresing 9.246132832459992\nCost Decresing 9.246127262651198\nCost Decresing 9.246121692853151\nCost Decresing 9.246116123065809\nCost Decresing 9.246110553289181\nCost Decresing 9.246104983523267\nCost Decresing 9.246099413768095\nCost Decresing 9.24609384402361\nCost Decresing 9.246088274289857\nCost Decresing 9.246082704566835\nCost Decresing 9.246077134854506\nCost Decresing 9.246071565152905\nCost Decresing 9.246065995462017\nCost Decresing 9.246060425781852\nCost Decresing 9.246054856112401\nCost Decresing 9.246049286453669\nCost Decresing 9.246043716805653\nCost Decresing 9.246038147168356\nCost Decresing 9.246032577541783\nCost Decresing 9.246027007925916\nCost Decresing 9.246021438320767\nCost Decresing 9.246015868726339\nCost Decresing 9.246010299142634\nCost Decresing 9.246004729569632\nCost Decresing 9.245999160007363\nCost Decresing 9.245993590455805\nCost Decresing 9.245988020914956\nCost Decresing 9.245982451384831\nCost Decresing 9.24597688186542\nCost Decresing 9.245971312356733\nCost Decresing 9.245965742858754\nCost Decresing 9.245960173371506\nCost Decresing 9.245954603894967\nCost Decresing 9.245949034429136\nCost Decresing 9.24594346497403\nCost Decresing 9.245937895529648\nCost Decresing 9.245932326095968\nCost Decresing 9.24592675667302\nCost Decresing 9.245921187260768\nCost Decresing 9.245915617859259\nCost Decresing 9.245910048468446\nCost Decresing 9.245904479088361\nCost Decresing 9.245898909718987\nCost Decresing 9.24589334036034\nCost Decresing 9.245887771012399\nCost Decresing 9.245882201675181\nCost Decresing 9.245876632348676\nCost Decresing 9.245871063032888\nCost Decresing 9.245865493727813\nCost Decresing 9.245859924433464\nCost Decresing 9.245854355149827\nCost Decresing 9.245848785876907\nCost Decresing 9.245843216614697\nCost Decresing 9.245837647363222\nCost Decresing 9.245832078122447\nCost Decresing 9.24582650889239\nCost Decresing 9.245820939673049\nCost Decresing 9.245815370464433\nCost Decresing 9.245809801266523\nCost Decresing 9.245804232079339\nCost Decresing 9.245798662902864\nCost Decresing 9.245793093737111\nCost Decresing 9.245787524582067\nCost Decresing 9.245781955437742\nCost Decresing 9.245776386304136\nCost Decresing 9.24577081718125\nCost Decresing 9.245765248069072\nCost Decresing 9.245759678967609\nCost Decresing 9.245754109876883\n\n\narray([[0.74752333],\n       [4.74721199]])\n\n\nAfter training we can clearly see we have reduced cost and have found appropriate value of theta\n\n# cost after traing model\ncost(X, y, theta)\n\n9.245754109876883\n\n\n\n# value of theta after training \ntheta\n\narray([[0.74752333],\n       [4.74721199]])\n\n\n\n# regression line after traing model\ndraw_points_and_lines(X, y, \"chirps/sec for the striped ground cricket\", \"temperature in degrees Fahrenheit\", theta)\n\n\n\n\nWe can clearly see we have fitted line to the points. Thus we have successfully used linear regression to train a model.\n\n\nPrediction\n\nx = np.array([19])\nhypothesis(x, theta)\n\narray([90.94455114])"
  },
  {
    "objectID": "posts/deploy-on-web-app/index.html",
    "href": "posts/deploy-on-web-app/index.html",
    "title": "Deploy ML Application on Azure App Service",
    "section": "",
    "text": "How to create an Azure Web App\nDifference between Azure Web App and App Service.\nDeploy your API on the Azure Web App\nTest your deployment\nBonus: How to connect the front-end to the API running on Web App.\n\nPrerequisites:\n\nAn Flask/FastAPI API is running locally.\nPostman - for API Testing\nAzure Account (Obviously!)\n\nThis is my folder structure. Out of these files 3 are important for deployment.\n\napp.py - Code for API is present here\nres18_10.pth - PyTorch trained model\nrequirement.txt - contains the dependent packages.( If you donâ€™t have this. You can get them doing pip freeze in the virtual environment)\n\nAll these files can be found here if want to look in more details Github repo: https://github.com/shashank2806/simple-classifier-demo\n\n\n\nFiles in the directory\n\n\n\nStep 0 : Test the API locally.\n\nTest the API in the virtual environment you have developed it. If you have not developed it in a virtual environment, I would strongly suggest that you create one and install all the dependencies into it using requirements.txt.\nTest it on postman.\n\nThis is my API running locally on postman, it has route named â€˜/predâ€™ which takes images as from-data.\nThis is the response when I upload this image of the cat. The model predicts it is a cat, cool.\n\n\n\nInput image of cat\n\n\nAs I have tested the API on my machine. Now it is ready for deployment. \n\n\nStep - 1: Create Azure Resources\nI am now going to create an Azure web app. A web app is the quickest method to deploy your APIs on the cloud. It supports both code and docker containers. In this blog, we are focusing on deployment through code.\n\n\n\n\n\nCreate a web app on the Azure portal. Select the subscription and Resource Group. You need to give it a unique name. Select OS and your python version. In my case, I have selected 3.10. Select the region.\nNow we have to select a app service plan. Most people have confusion between web app and app service.(Even both terms are used interchangeably) App service is the hardware on which you web app is deployed. Single App service can host multiple web apps. Keep this in mind when selecting your app service plan. I am selecting B1 plan, which is capable enough to host this API.\n \nClick Review+Create\nThe web app is created. A URL is also assigned - https://pytorch-demo.azurewebsites.net/\nThis is the URL where the web app will be hosted, There is nothing there right now.\n\n\n\n\n\n\n\nStep 2: Push code to the Web App\n\nOn the Azure Portal, go to the Deployment centre and select local git as the deployment source. You will get the git clone path, and username and password in the Credentials tab. Tip: The username is just ${web app name}, in my case $pytorch-demo, Do not enter the full username provided. \nGo to the directory containing the code. You can also test it on my demo code. Clone the github repo using git clone https://github.com/shashank2806/simple-classifier-demo.git You need git to be initialised (git init) in the directory, and commit (git commit) the changes you want to be uploaded.\nAdd a new remote to push code. I had initially one remote(origin) pointing to my Github. I have added new remote named azure which connects to web app. Use git remote add <git-clone-uri> to add remote. \nNow push the code to Azure using - git push azure master \nNow wait for few minutes, you can see the logs on the screen. Wait until the deployment succeeds.\n\nVoila The deplyment to the cloud is done! Now we can test it on postman.\n\n\n\n\n\nGreat!! As you can see, We have deployed the API over the cloud, now anyone can access it. We just need to give the user Endpoint and Key.\n\n\nStep 3: Bonus- Connect it with the front-end.\nWe have deployed our backend API on the web app. As you may have noticed there is an index.html in the directory. This contains a very simple front-end. We can connect the back-end API to the front-end.\nThe index.html is hosted through GitHub Pages(free hosting). The the hosted URL is https://shashankshekhar.me/simple-classifier-demo/\nIf you look into index.html, You will find a JavaScript - Fetch is used for calling the API. (You can get the code snippet to connect with help of postman.)\n    var requestOptions = {\n        method: \"POST\",\n        body: formData,\n        redirect: \"follow\",\n    };\n\n    // Change endpoint here\n    fetch(\"https://pytorch-demo.azurewebsites.net/pred\", requestOptions)\nYou can make some minor changes on this front-end to tailor it to your need. I have changed the Endpoint URL to the web app.\nLetâ€™s try with our cat image. On this front-end.\n Voila! We have got the result, The API is taking to the font-end, the request we are making on our web browser is going to our API and fetching the results from there.\nThe API might not be responsing by the time you are looking at this web page - I will delete the App Service later.\n\n\nFinal Words\nWe now know:\n\nHow to deploy your API on the Azure app service\nTest the API through Postman\nHow to connect it to the front end. (or how to communicate with the frontend engineer about your ML API. Give them, endpoints, routes and keys/schema)\n\nThis method will work in most cases, where there are not complex dependencies, sometimes, there are OS-based dependencies for which we will have to deploy through Docker.\nEnjoy. Happy Learning!!!"
  }
]